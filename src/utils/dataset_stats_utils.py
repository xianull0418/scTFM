import os
import tiledbsoma
import math
import multiprocessing
from concurrent.futures import ProcessPoolExecutor
from typing import Tuple, List

def _count_one_shard(args: Tuple[str, int]) -> int:
    """
    å•ä¸ª Worker çš„ä»»åŠ¡ï¼šè®¡ç®—ä¸€ä¸ªåˆ†ç‰‡é‡Œç¬¦åˆ split_label çš„ç»†èƒæ•°
    å¿…é¡»æ˜¯é¡¶å±‚å‡½æ•°ï¼Œä»¥ä¾¿ pickle åºåˆ—åŒ–ã€‚
    """
    uri, split_label = args
    try:
        # æ˜¾å¼åˆ›å»ºç‹¬ç«‹çš„ Contextï¼Œé¿å…å¤šè¿›ç¨‹å…±äº« Context å¯¼è‡´çš„ C++ å±‚æ­»é”
        ctx = tiledbsoma.SOMATileDBContext()
        with tiledbsoma.Experiment.open(uri, context=ctx) as exp:
            query = exp.obs.read(
                value_filter=f"split_label == {split_label}",
                column_names=["soma_joinid"]
            ).concat()
            return len(query)
    except Exception:
        return 0

def get_dataset_stats(
    root_dir: str, 
    split_label: int, 
    batch_size: int, 
    num_workers: int = 16, 
    world_size: int = 1
) -> Tuple[int, int]:
    """
    å¤šè¿›ç¨‹å¹¶è¡Œæ‰«æ TileDB æ•°æ®é›†ï¼Œè®¡ç®—æ€»ç»†èƒæ•°å’Œæ­¥æ•°ã€‚
    
    Args:
        root_dir: æ•°æ®é›†æ ¹ç›®å½•
        split_label: 0=Train, 1=Val
        batch_size: å•å¡ Batch Size
        num_workers: å¹¶è¡Œæ‰«æçš„è¿›ç¨‹æ•° (å»ºè®®è®¾ä¸º CPU æ ¸å¿ƒæ•°çš„ä¸€åŠ)
        world_size: DDP æ€» GPU æ•° (ç”¨äºè®¡ç®— Global Batch Size)
        
    Returns:
        (total_cells, total_steps)
    """
    if not os.path.exists(root_dir):
        print(f"âš ï¸ [Stats] è·¯å¾„ä¸å­˜åœ¨: {root_dir}")
        return 0, 0
        
    sub_uris = sorted([
        os.path.join(root_dir, d) 
        for d in os.listdir(root_dir) 
        if os.path.isdir(os.path.join(root_dir, d))
    ])
    
    if not sub_uris:
        return 0, 0
    
    print(f"ğŸ“Š [Stats] å¯åŠ¨å¤šè¿›ç¨‹æ‰«æ {len(sub_uris)} ä¸ª Shards (Split={split_label})...")
    
    # å‡†å¤‡ä»»åŠ¡å‚æ•°
    tasks = [(uri, split_label) for uri in sub_uris]
    total_cells = 0
    
    # åŠ¨æ€è°ƒæ•´ worker æ•°ï¼Œä¸è¶…è¿‡ä»»åŠ¡æ•°ä¹Ÿä¸è¶…è¿‡ CPU æ ¸å¿ƒæ•°
    max_workers = min(num_workers, len(tasks), os.cpu_count() or 1)

    # ä½¿ç”¨ ProcessPoolExecutor å¹¶è¡Œå¤„ç†
    # TileDB çš„ C++ æ ¸å¿ƒåœ¨ ThreadPool ä¸‹å¯èƒ½ä¼šæœ‰ GIL æˆ–é”ç«äº‰é—®é¢˜ï¼ŒProcessPool æ›´ç¨³
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        results = executor.map(_count_one_shard, tasks)
        total_cells = sum(results)
    
    # è®¡ç®— DDP ç¯å¢ƒä¸‹çš„ Global Batch Size
    global_batch_size = batch_size * world_size
    if global_batch_size == 0:
        return 0, 0
        
    total_steps = math.ceil(total_cells / global_batch_size)
    
    print(f"âœ… [Stats] å®Œæˆ: {total_cells} cells | Global Batch: {global_batch_size} | Epoch Steps: {total_steps}")
    
    return total_cells, total_steps
